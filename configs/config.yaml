# Main configuration
defaults:
  - data: loquacious
  - training: production
  - _self_

# Model configuration (must match ASRConfig parameter names)
model:
  audio_model_id: zai-org/GLM-ASR-Nano-2512
  text_model_id: Qwen/Qwen3-0.6B
  system_prompt: "You are a helpful speech transcription assistant."
  projector_type: mlp  # Options: mlp, mosa, moe, qformer

  # Projector settings
  projector_pool_stride: 4
  projector_hidden_dim: null

  # MoE settings (for moe/mosa projector types)
  num_experts: 4
  num_experts_per_tok: 2
  router_aux_loss_coef: 0.01

  # Generation settings
  max_new_tokens: 256

# Hydra output directories
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job:
    chdir: true

# Early stopping (set patience to enable)
early_stopping:
  patience: null
  threshold: 0.0

verbose: false
