# Complete multi-task dataset configuration with all four tasks
datasets:
  # Transcription task - LoquaciousSet
  - path: speechbrain/LoquaciousSet
    name: clean
    audio_column: wav
    text_column: text
    task: transcribe  # Mark as transcription task
    train_splits:
      - train
    eval_splits:
      - dev
    sampling_weight: 0.3  # 30% of training samples

  # Continuation task - SODA-Audio
  - path: fixie-ai/soda-audio
    name: default
    audio_column: audio_second_last_turn
    text_column: alt_last_turn
    task: continue  # Mark as continuation task
    train_splits:
      - train
    eval_splits:
      - validation
    sampling_weight: 0.25  # 25% of training samples

  # Description task - AudioSet Strong
  - path: CLAPv2/audioset_strong
    audio_column: audio
    text_column: text
    task: describe  # Mark as description task
    train_splits:
      - train
    eval_splits:
      - validation
    sampling_weight: 0.25  # 25% of training samples

  # Emotion task - CAMEO
  - path: amu-cai/CAMEO
    audio_column: audio
    text_column: emotion
    task: emotion  # Mark as emotion recognition task
    train_splits:
      - crema_d[:80%]
    eval_splits:
      - crema_d[80%:]
    sampling_weight: 0.2  # 20% of training samples

# Data filtering
max_audio_seconds: 15.0

# Audio processing
sample_rate: 16000

# SpecAugment parameters (wav2vec2-style masking)
mask_time_prob: 0.05
mask_time_length: 10
mask_feature_prob: 0.0
mask_feature_length: 10

# Processing options
dataset_cache_dir: ${hydra:runtime.cwd}/datasets_cache
num_proc: 8
max_train_samples: null
max_eval_samples: 500  # Keep eval manageable
use_streaming: true