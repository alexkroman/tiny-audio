# @package _global_

# Stage 1 configuration - Full PEFT Training
# Projector (trainable) + Encoder LoRA + Decoder LoRA
# This is the most comprehensive training approach with ~18M trainable parameters
defaults:
  - override /model: large
  - override /data: loquacious_large
  - override /training: production
  - override /encoder_lora: default

model:
  # Load the pretrained model from Hub (this loads the projector weights)
  pretrained_model_path: "mazesmazes/tiny-audio"
  
  decoder_model_name: HuggingFaceTB/SmolLM3-3B
  encoder_model_name: facebook/hubert-xlarge-ls960-ft

  # Projector configuration
  audio_downsample_rate: 5
  projector_hidden_dim: 8192

# Encoder LoRA Configuration
encoder_lora:
  r: 8  # LoRA rank for encoder
  lora_alpha: 8  # Scaling factor (alpha/r = 1.0)
  target_modules: ["q_proj", "k_proj"]  # HuBERT attention projections
  lora_dropout: 0.0
  bias: none

# Decoder LoRA Configuration
peft:
  peft_method: lora  # Enable LoRA fine-tuning on decoder
  r: 64  # LoRA rank for decoder (matching encoder)
  lora_alpha: 32  # Scaling factor (alpha/r = 1.0)
  target_modules: ["q_proj", "v_proj"]  
  bias: none  # No bias training
  task_type: CAUSAL_LM  # Causal language modeling
  lora_dropout: 0.0  
  inference_mode: false  # Training mode

training:
  # Hub configuration
  push_to_hub: true
  hub_model_id: "mazesmazes/tiny-audio"
  hub_strategy: "checkpoint"
  hub_private_repo: false

  per_device_train_batch_size: 5
  per_device_eval_batch_size: 5
  gradient_accumulation_steps: 5
  eval_accumulation_steps: 5

  # Learning rate - Higher for LoRA

  learning_rate: 1.0e-4
  # learning_rate: .00007 try this learning rate if you reach a plateau
  
  warmup_steps: 100
  lr_scheduler_type: "cosine_with_min_lr"
  lr_scheduler_kwargs: {"min_lr_rate": 0.1}

  # Optimization
  weight_decay: 0.0
  max_grad_norm: 1.0

  # Memory optimization
  torch_compile: false  # Disabled - causes issues with encoder LoRA
  gradient_checkpointing: false

  # Training duration
  max_steps: 25000

  # Reproducibility
  seed: 47
  ignore_data_skip: true

# Data configuration
data:
  max_audio_seconds: 16.0

# Early stopping configuration
early_stopping:
  patience: null
  threshold: 0.0
