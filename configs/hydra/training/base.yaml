# Base training configuration
output_dir: ./outputs/${now:%Y%m%d_%H%M%S}

# Logging
logging_steps: 10
report_to: wandb

# Evaluation
eval_strategy: steps
eval_steps: 100

# Saving
save_strategy: steps
save_steps: 100
save_total_limit: 2
load_best_model_at_end: false
metric_for_best_model: eval_loss
greater_is_better: false

# Hub
push_to_hub: false

# Optimizer
learning_rate: 1.0e-4
weight_decay: 0.01
max_grad_norm: 1.0
warmup_steps: 1000
lr_scheduler_type: cosine_with_min_lr
lr_scheduler_kwargs:
  min_lr_rate: 0.1

# Training
max_steps: 50000
seed: 42

# Model runtime settings
model_dtype: float32
attn_implementation: eager

# Required by HF Trainer
remove_unused_columns: false
label_names:
  - labels