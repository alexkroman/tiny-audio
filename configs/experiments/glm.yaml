# @package _global_
# Stage 2: LoRA fine-tuning of LLM with frozen projector
# Requires stage 1 checkpoint with trained projector

model:
  audio_model_id: zai-org/GLM-ASR-Nano-2512
  text_model_id: Qwen/Qwen3-1.7B
  encoder_stride: 2  # GLM encoder has conv2 with stride=2
  projector_type: mlp

  # LoRA configuration
  use_lora: true
  lora_r: 64
  lora_alpha: 32
  lora_dropout: 0.0
  lora_target_modules:
    - v_proj
    - q_proj

training:
  hub_model_id: "mazesmazes/tiny-audio-glm"
  warmup_steps: 1000
  per_device_train_batch_size: 12
  per_device_eval_batch_size: 12
  gradient_accumulation_steps: 2
  num_train_epochs: 1
  save_steps: 50
  eval_steps: 50
