# @package _global_

model:
  audio_model_id: zai-org/GLM-ASR-Nano-2512
  text_model_id: Qwen/Qwen3-1.7B
  projector_type: mlp

# Use large dataset config
data:
  datasets:
    - path: speechbrain/LoquaciousSet
      name: large
      audio_column: wav
      text_column: text
      task: transcribe
      train_splits:
        - train
      eval_splits:
        - dev

training:
  hub_model_id: "mazesmazes/tiny-audio"
  weight_decay: 0.01
  warmup_steps: 1000
  per_device_train_batch_size: 14
  per_device_eval_batch_size: 14
  gradient_accumulation_steps: 2
  num_train_epochs: 1
  save_steps: 500
  eval_steps: 1000
