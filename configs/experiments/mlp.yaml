# @package _global_
# Stage 3: Joint fine-tuning of projector + LoRA adapter
# Unfreezes projector to jointly optimize both components
#
# Usage:
#   poetry run python scripts/train.py +experiments=mlp_fine_tune
#
# Requires a pretrained Stage 2 model (projector + LoRA trained)

model:
  projector_type: mlp
  projector_pool_stride: 4
  audio_model_id: zai-org/GLM-ASR-Nano-2512
  text_model_id: Qwen/Qwen3-1.7B

training:
  hub_model_id: "mazesmazes/tiny-audio"
  learning_rate: 2e-3  # Higher LR to train projector
  warmup_steps: 1000  # Reduced from 2000
  lr_scheduler_type: polynomial
  lr_scheduler_kwargs:
    power: 0.5
  seed: 42  # Different seed for data ordering
  per_device_train_batch_size: 14
  per_device_eval_batch_size: 14
  gradient_accumulation_steps: 1
  num_train_epochs: 4
  save_steps: 10000
  eval_steps: 10000

  label_smoothing_factor: 0.1
  weight_decay: 0.0

  use_specaugment: true

  num_time_masks: 1
  time_mask_length: 100
  num_freq_masks: 1
  freq_mask_length: 27
