# Multitask dataset configuration
# Azeros-style weighting: downweight large ASR, cap upsample at ~10x

datasets:
  # Loquacious medium - main ASR dataset (~80%)
  - path: speechbrain/LoquaciousSet
    name: medium
    audio_column: wav
    text_column: text
    task: transcribe
    train_splits: [train]
    eval_splits: [dev]
    target_samples: 750000

  # Large ASR datasets - heavily downweight (like commonvoice/voxceleb in azeros)
  - path: mazesmazes/sift-audio
    audio_column: audio
    text_column: text
    task: sift
    train_splits: [commonvoice]
    eval_splits: [commonvoice]
    target_samples: 15000  # downsampled from 100k

  - path: mazesmazes/sift-audio
    audio_column: audio
    text_column: text
    task: sift
    train_splits: [podcast]
    eval_splits: [podcast]
    target_samples: 15000  # downsampled from 149k

  # Medium emotion - moderate upsample
  - path: mazesmazes/sift-audio
    audio_column: audio
    text_column: text
    task: sift
    train_splits: [esd]
    eval_splits: [esd]
    target_samples: 50000  # ~3x from 17.5k

  - path: mazesmazes/sift-audio
    audio_column: audio
    text_column: text
    task: sift
    train_splits: [crema_d]
    eval_splits: [crema_d]
    target_samples: 50000  # ~7x from 7.4k

  # Small emotion - cap at ~10x upsample (like azeros ravdess/tess)
  - path: mazesmazes/sift-audio
    audio_column: audio
    text_column: text
    task: sift
    train_splits: [tess]
    eval_splits: [tess]
    target_samples: 28000  # 10x from 2.8k

  - path: mazesmazes/sift-audio
    audio_column: audio
    text_column: text
    task: sift
    train_splits: [ravdess]
    eval_splits: [ravdess]
    target_samples: 14000  # 10x from 1.4k

  - path: mazesmazes/sift-audio
    audio_column: audio
    text_column: text
    task: sift
    train_splits: [savee]
    eval_splits: [savee]
    target_samples: 5000  # ~10x from 480

# Audio processing
sample_rate: 16000

# Processing options
dataset_cache_dir: ${hydra:runtime.cwd}/datasets_cache
max_eval_samples: 2000
