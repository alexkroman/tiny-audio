# Multitask dataset configuration for SIFT training
# Combines LoquaciousSet (ASR) with paralinguistic datasets
#
# Generate SIFT data first with: ta runpod sift <host> <port>
# (outputs to mazesmazes/sift-audio by default)
#
# Dataset columns:
#   - audio: audio data
#   - text: transcription
#   - sift_response: LLM-generated response
#   - emotion, gender, age: paralinguistic labels

datasets:
  # CREMA-D: emotion + text (also used for eval)
  - path: ${oc.env:SIFT_DATASET_REPO,mazesmazes/sift-audio}
    audio_column: audio
    text_column: text
    sift_response_column: sift_response
    emotion_column: emotion
    train_splits:
      - crema_d
    eval_splits:
      - crema_d
    sampling_weight: 2.0

  # RAVDESS: emotion + gender + text
  - path: ${oc.env:SIFT_DATASET_REPO,mazesmazes/sift-audio}
    audio_column: audio
    text_column: text
    sift_response_column: sift_response
    emotion_column: emotion
    gender_column: gender
    train_splits:
      - ravdess
    eval_splits:
      - ravdess
    sampling_weight: 2.0

  # MELD: emotion + text (TV show Friends dialogue)
  - path: ${oc.env:SIFT_DATASET_REPO,mazesmazes/sift-audio}
    audio_column: audio
    text_column: text
    sift_response_column: sift_response
    emotion_column: emotion
    train_splits:
      - meld
    eval_splits:
      - meld
    sampling_weight: 2.0

# Audio processing
sample_rate: 16000

# Processing options
dataset_cache_dir: ${hydra:runtime.cwd}/datasets_cache
max_train_samples: null
max_eval_samples: null  # Use all available samples
